{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Generation of labeled voltage phasors under both physical attack and FDI attack via SMART-DS dataset and OpenDSS software:\n",
                "\n",
                "Generate voltage phasors with attack labels via:\n",
                "  1 SMART-DS, a large open-source dataset of distribution networks with realistic (active/reactive power) load profile in different voltage levels (see details below)\n",
                "  2 OpenDSS, a widely-used open-source software for 3-phase unbalanced distribution network power flow analysis\n",
                "\n",
                "Two types of attacks are considered:\n",
                "  1 Physical attacks, which manipulate VV/VW control curve of inverters\n",
                "  2 Stealthy false data injection (FDI) attacks, which manipulate measurement to bypass traditional bad data detection"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# SMART-DS dataset details:\n",
                "\n",
                "In SMART-DS dataset, 3-year load profiles are included: 2016, 2017, 2018. In addition, more than 3 voltage levels are considered:\n",
                "  1 230 kV: subtransmission level\n",
                "  2 69 kV: substation level\n",
                "  3 4 kV ~ 25 kV: feeder levels \n",
                "\n",
                "The data structure of SMART-DS dataset is organized as follows:\n",
                "SMART-DS\n",
                "└─── <GIS>\n",
                "└─── <PLACEMENTS>\n",
                "└─── <YEARS>\n",
                "    └─── <DATASETS>\n",
                "         └──── full_dataset_analysis\n",
                "         └─── <SUB-REGIONS>\n",
                "              └──── profiles\n",
                "              └──── cyme_profiles\n",
                "              └──── load_data\n",
                "              └──── solar_data\n",
                "              └──── load_curves\n",
                "              └──── <SCENARIOS>\n",
                "                     └──── metrics.csv\n",
                "                     └──── cyme\n",
                "                     └──── opendss\n",
                "                     │     └──── analysis\n",
                "                     │     └──── <SUBSTATIONS>\n",
                "                     │           └──── analysis\n",
                "                     │           └──── <FEEDERS>\n",
                "                     │                 └──── analysis\n",
                "                     └──── opendss_no_loadshapes\n",
                "                           └──── <SUBSTATIONS>\n",
                "                                 └──── <FEEDERS>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# How to start:\n",
                "1. Unzip the .zip file\n",
                "2. Create new conda environment with python=3.11\n",
                "3. In the new conda env: \n",
                "    pip install .\n",
                "    pip install torch==2.0.1 torchvision torchaudio --index-url https://download.pytorch.org/whl/cu117\n",
                "    pip install cplxmodule\n",
                "    pip3 install scikit-learn\n",
                "    pip install numpy==1.24.4\n",
                "    pip install pyarrow\n",
                "4. Restart and run this .ipynb file"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 0 import\n",
                "from data_loader import RolloutStorage, data_loader_FDIPhy\n",
                "from graph_loader import single2batch_phy\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import numpy as np\n",
                "from cplxmodule import cplx\n",
                "from cplxmodule.nn.modules import CplxConv1d\n",
                "from cplxmodule.nn.modules import CplxLinear\n",
                "from model.layers import ChebGraphConv\n",
                "from model.utility import calc_gso, calc_chebynet_gso, cnv_sparse_mat_to_coo_tensor\n",
                "from cplxmodule.nn import CplxToCplx\n",
                "from torch.autograd import Variable\n",
                "import opendssdirect as dss\n",
                "import os\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import scipy.sparse as sps\n",
                "from scipy.sparse import csc_matrix, diags\n",
                "import random\n",
                "import measurements\n",
                "from scipy.sparse.linalg import svds\n",
                "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
                "#random.seed(100) \n",
                "\n",
                "# 0 check GPU\n",
                "# Check if CUDA is available\n",
                "print(\"CUDA Available:\", torch.cuda.is_available())\n",
                "if torch.cuda.is_available():\n",
                "    # Get the current device\n",
                "    current_device = torch.cuda.current_device()\n",
                "    print(\"Current CUDA Device Index:\", current_device)\n",
                "    # Get device name\n",
                "    print(\"Current CUDA Device Name:\", torch.cuda.get_device_name(current_device))\n",
                "    # Check CUDA version\n",
                "    print(\"CUDA Version:\", torch.version.cuda)\n",
                "# check version of numpy and torch\n",
                "print(\"NumPy version:\", np.__version__)\n",
                "print(\"PyTorch version:\", torch.__version__)\n",
                "# check if NumPy is available\n",
                "try:\n",
                "    arr = np.array([1, 2, 3], dtype=np.float32)\n",
                "    print(\"NumPy array:\", arr)\n",
                "except Exception as e:\n",
                "    print(\"NumPy error:\", e)\n",
                "# check if Numpy is compatible with PyTorch\n",
                "try:\n",
                "    tensor = torch.from_numpy(arr)\n",
                "    print(\"Torch tensor:\", tensor)\n",
                "except Exception as e:\n",
                "    print(\"Torch error:\", e)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1 select a 3-phase unbalanced distribution system from the SMART-DS dataset\n",
                "# according to the specific data structure of SMART-DS dataset\n",
                "current_dir = os.getcwd()\n",
                "#print(\"current work folder:\", current_dir)\n",
                "area = 'P4U'\n",
                "sce = 'scenarios'\n",
                "timeseries = 'base_timeseries'\n",
                "loadshape = 'opendss_no_loadshapes'\n",
                "substation = 'p4uhs0_4'\n",
                "feeder = 'p4uhs0_4--p4udt4'\n",
                "Master_dss = os.path.join(area, sce, timeseries, loadshape, substation, feeder, 'Master.dss')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2 initialize OpenDSS\n",
                "dss.Basic.ClearAll() # Initialize OpenDSS\n",
                "result = dss.run_command(\"Redirect \" + Master_dss)\n",
                "\n",
                "NumBus = dss.Circuit.NumBuses()\n",
                "NumNode = dss.Circuit.NumNodes()\n",
                "print(NumBus)\n",
                "print(NumNode)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3 extract Y matrix of the selected SMART-DS example using OpenDSS\n",
                "Y_NodeOrder = dss.Circuit.YNodeOrder()\n",
                "Y_sparse = sps.csc_matrix(dss.YMatrix.getYsparse())\n",
                "# Y_sparse type is scipy.sparse.csc_matrix\n",
                "# e.g., Y_sparse = csc_matrix((data, (row, col)), shape=(n, n))\n",
                "# Extract diagonal matrix from Ybus\n",
                "Dmat = diags(Y_sparse.diagonal(), format='csc')\n",
                "# Compute the inverse square root of the diagonal matrix\n",
                "Dmat_inv_sqrt = diags(1 / np.sqrt(Dmat.diagonal()), format='csc')\n",
                "# Normalize the admittance matrix\n",
                "Y_norm = Dmat_inv_sqrt @ Y_sparse @ Dmat_inv_sqrt\n",
                "# Filter small values in Y_norm\n",
                "Y_norm = Y_norm.toarray()  # Convert to dense matrix for element-wise operations\n",
                "real_small = np.abs(Y_norm.real) < 1e-8\n",
                "imag_small = np.abs(Y_norm.imag) < 1e-8\n",
                "Y_norm.real[real_small] = 0\n",
                "Y_norm.imag[imag_small] = 0\n",
                "# Convert back to sparse format\n",
                "Y_norm_sparse = csc_matrix(Y_norm)\n",
                "Y_dense = Y_norm_sparse.toarray()\n",
                "from scipy.linalg import svd\n",
                "# SVD of normalized Y matrix\n",
                "U, S, Vh = svd(Y_dense, full_matrices=False)\n",
                "# Select top-k left singular vectors\n",
                "k = 80\n",
                "U_k = U[:, :k]\n",
                "print(Y_NodeOrder)\n",
                "print(Y_norm_sparse)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4 extract the PQ load profile for the selected SMART-DS example\n",
                "# according to the specific data structure of SMART-DS dataset\n",
                "Loads_dss = os.path.join(area, sce, timeseries, loadshape, substation, feeder, 'Loads.dss')\n",
                "load_data_folder = os.path.join(area, 'load_data')\n",
                "# Initialize an empty dictionary to store load mappings\n",
                "load_profile_map = {}\n",
                "# Open the Loads.dss file for reading\n",
                "with open(Loads_dss) as f_load:\n",
                "    # Iterate through each line in the file\n",
                "    for row in f_load.readlines():\n",
                "        # Split the line into tokens (words) using whitespace as a delimiter\n",
                "        sp = row.split()\n",
                "        # Initialize temporary variables for this line\n",
                "        name = None  # Load name\n",
                "        profile = None  # Time series profile file name\n",
                "        multiplier = 1  # Default multiplier for loads\n",
                "        # Iterate through each token in the line\n",
                "        for token in sp:\n",
                "            # If the token represents a load definition, extract the load name\n",
                "            if token.startswith('Load.'):\n",
                "                # Extract the load name after the 'Load.' prefix\n",
                "                name = token.split('.')[1]\n",
                "                # Check if the load name ends with '_1' or '_2'\n",
                "                # These indicate center-tap loads, so we set the multiplier to 0.5\n",
                "                if name.endswith('_1') or name.endswith('_2'):\n",
                "                    multiplier = 0.5  # Center-tap loads\n",
                "            # If the token contains the yearly time series profile information\n",
                "            # e.g., !yearly=com_kw_16145_pu\n",
                "            if token.startswith('!yearly'):\n",
                "                # Extract the profile information after the '=' sign\n",
                "                profile_raw = token.split('=')[1]\n",
                "                # Special case: if the profile indicates a mesh load\n",
                "                if 'mesh' in profile_raw:\n",
                "                    profile = 'mesh'\n",
                "                else:\n",
                "                    # Parse the profile name into components and construct the .parquet file name\n",
                "                    profile_sp = profile_raw.split('_')\n",
                "                    profile = profile_sp[0] + '_' + profile_sp[2] + '.parquet'  # e.g., com_16145.parquet\n",
                "            # If a profile has been identified, store the load information in the dictionary\n",
                "            if profile is not None:\n",
                "                # Add the load name as the key and a tuple (profile, multiplier) as the value\n",
                "                load_profile_map[name] = (profile, multiplier)\n",
                "# The resulting `load_profile_map` contains mappings of load names to their respective\n",
                "# time series profile files and multipliers (for center-tap loads).\n",
                "\n",
                "sample_profile = next(iter(load_profile_map.values()))[0]\n",
                "parquet_path_sample = os.path.join(load_data_folder, sample_profile)\n",
                "total_timepoints = len(pd.read_parquet(parquet_path_sample))\n",
                "sampling_rate = 20 "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Step 5: Initialize the PV inverter ---\n",
                "\n",
                "# Select 30 PV inverters (feeder names)\n",
                "pv_feeder = list(load_profile_map.keys())[:30]  \n",
                "num_pv = len(pv_feeder)\n",
                "\n",
                "# Function to determine whether a PV inverter is connected to phase 2\n",
                "def is_phase2(feeder_name):\n",
                "    try:\n",
                "        dss.Loads.Name(feeder_name)  # Activate the load\n",
                "        nodes = dss.CktElement.NodeOrder()  # Phase numbers it's connected to\n",
                "        return 2 in nodes\n",
                "    except Exception as e:\n",
                "        print(f\"Warning: Could not resolve feeder {feeder_name} → {e}\")\n",
                "        return False\n",
                "\n",
                "# Print connected phases for verification (optional debug)\n",
                "print(\"\\n--- PV Feeder Phase Connection ---\")\n",
                "for feeder in pv_feeder:\n",
                "    dss.Loads.Name(feeder)\n",
                "    phases = dss.CktElement.NodeOrder()\n",
                "    print(f\"{feeder} → Connected Phases: {phases}\")\n",
                "\n",
                "# Determine which PV inverters are connected to phase 2\n",
                "pv_phase2_flags = [is_phase2(feeder) for feeder in pv_feeder]\n",
                "\n",
                "\n",
                "# Initialize VV/VW control parameters\n",
                "# Shape: (num_pv, 3 phases, 5 control points)\n",
                "eta_base = np.array([0.95, 0.97, 1.03, 1.05, 1.10])\n",
                "eta = np.tile(eta_base, (num_pv, 3, 1))  # Same for all phases initially\n",
                "\n",
                "# Set PV inverter rated power\n",
                "sv_power = 2.96  # kVA\n",
                "\n",
                "# Generate random PV active power profiles\n",
                "np.random.seed(100)\n",
                "pv_power = np.random.uniform(1.0, 1.2, size=(total_timepoints, num_pv))\n",
                "\n",
                "# Reshape feeder names to match OpenDSS node format (e.g., load_p4ulv5_2 → p4ulv5.2)\n",
                "pv_feeder_reshape = [feeder.replace(\"load_\", \"\").replace(\"_\", \".\") for feeder in pv_feeder]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Step 6: Define functions ---\n",
                "\n",
                "def inject_false2(eta, pv_phase2_flags, attack_fraction=0.8, new_curve=None):\n",
                "    \n",
                "    # Simulates a stealthy physical attack by modifying the VV/VW control curve of selected phase-2 PV inverters.\n",
                "\n",
                "    # Parameters:\n",
                "    # - eta: ndarray, shape (num_pv, 3, 5), baseline control curves for all PV inverters.\n",
                "    # - pv_phase2_flags: list of bools, indicates which PVs are connected to phase 2.\n",
                "    # - attack_fraction: float, fraction of phase-2 PVs to be attacked (default = 0.8).\n",
                "    # - new_curve: ndarray, shape (5,), optional malicious control curve to apply (default if None).\n",
                "\n",
                "    # Returns:\n",
                "    # - eta_comm: ndarray, modified control curves with attack injected.\n",
                "    # - attack_label: ndarray, shape (num_pv,), binary labels indicating attacked PVs (1 = attacked).\n",
                "    \n",
                "    eta_comm = eta.copy()\n",
                "    attack_label = np.zeros(eta.shape[0], dtype=int)\n",
                "  \n",
                "    phase2_indices = [i for i, is_p2 in enumerate(pv_phase2_flags) if is_p2]\n",
                "  \n",
                "    num_phase2 = len(phase2_indices)\n",
                "    num_to_attack = int(np.floor(num_phase2 * attack_fraction))\n",
                "    \n",
                "    if num_to_attack > 0:\n",
                "        selected = np.random.choice(phase2_indices, num_to_attack, replace=False)\n",
                "    else:\n",
                "        selected = []\n",
                "\n",
                "    if new_curve is None:\n",
                "        new_curve = np.array([0.98, 0.99, 1.01, 1.02, 1.10])\n",
                "\n",
                "    for idx in selected:\n",
                "        eta_comm[idx, 1, :] = new_curve\n",
                "        attack_label[idx] = 1\n",
                "\n",
                "    return eta_comm, attack_label\n",
                "\n",
                "def VW_func(Vm_pv_lp_t1, pv_power, eta, phase_idx):\n",
                "\n",
                "    #Volt-Watt (VW) control logic. Determines how much active power is injected based on voltage magnitude.\n",
                "\n",
                "    # Parameters:\n",
                "    # - Vm_pv_lp_t1: ndarray, smoothed voltage magnitudes at each PV node.\n",
                "    # - pv_power: ndarray, available PV active power at each node.\n",
                "    # - eta: ndarray, control curves for each PV.\n",
                "    # - phase_idx: int, phase being considered (0-based index).\n",
                "\n",
                "    # Returns:\n",
                "    # - Pw_inj: ndarray, real power injection per node.\n",
                "    \n",
                "    eta_4 = eta[:, phase_idx, 3]\n",
                "    eta_5 = eta[:, phase_idx, 4]\n",
                "    Pw_inj = np.zeros_like(Vm_pv_lp_t1)\n",
                "    for i in range(len(Vm_pv_lp_t1)):\n",
                "        if Vm_pv_lp_t1[i] <= eta_4[i]:\n",
                "            Pw_inj[i] = pv_power[i]\n",
                "        elif Vm_pv_lp_t1[i] <= eta_5[i]:\n",
                "            Pw_inj[i] = (eta_5[i] - Vm_pv_lp_t1[i]) / (eta_5[i] - eta_4[i]) * pv_power[i]\n",
                "        else:\n",
                "            Pw_inj[i] = 0\n",
                "    return Pw_inj\n",
                "\n",
                "def VV_func(Vm_pv_lp_t1, qv_power, eta_phase):\n",
                "\n",
                "    # Volt-Var (VV) control logic. Determines how much reactive power is injected based on voltage magnitude.\n",
                "\n",
                "    # Parameters:\n",
                "    # - Vm_pv_lp_t1: ndarray, smoothed voltage magnitudes at each PV node.\n",
                "    # - qv_power: ndarray, max available reactive power.\n",
                "    # - eta_phase: ndarray, VV control curve parameters for the selected phase (shape: num_pv x 5).\n",
                "\n",
                "    # Returns:\n",
                "    # - Qv_inj: ndarray, reactive power injection per node.\n",
                "\n",
                "    eta_1 = eta_phase[:, 0]\n",
                "    eta_2 = eta_phase[:, 1]\n",
                "    eta_3 = eta_phase[:, 2]\n",
                "    eta_4 = eta_phase[:, 3]\n",
                "\n",
                "    Qv_inj = np.zeros_like(Vm_pv_lp_t1)\n",
                "    for i in range(len(Vm_pv_lp_t1)):\n",
                "        V = Vm_pv_lp_t1[i]\n",
                "        qmax = qv_power[i]\n",
                "\n",
                "        if V <= eta_1[i]:\n",
                "            Qv_inj[i] = qmax\n",
                "        elif V <= eta_2[i]:\n",
                "            Qv_inj[i] = (eta_2[i] - V) / (eta_2[i] - eta_1[i]) * qmax\n",
                "        elif V <= eta_3[i]:\n",
                "            Qv_inj[i] = 0\n",
                "        elif V <= eta_4[i]:\n",
                "            Qv_inj[i] = -(V - eta_3[i]) / (eta_4[i] - eta_3[i]) * qmax\n",
                "        else:\n",
                "            Qv_inj[i] = -qmax\n",
                "\n",
                "    return Qv_inj\n",
                "\n",
                "\n",
                "def VV_VW_func(Vm_pv, eta, pv_power, sv_power, Vm_pv_lp_t0, pinj_pv_t0, qinj_pv_t0, target_phase=2):\n",
                "\n",
                "    # Combined VV and VW logic with dynamic filtering to compute PV injection at a given timestep.\n",
                "\n",
                "    #     Parameters:\n",
                "    #     - Vm_pv: ndarray, current voltage magnitudes.\n",
                "    #     - eta: ndarray, VV/VW control curves.\n",
                "    #     - pv_power: ndarray, available real power.\n",
                "    #     - sv_power: float, rated inverter power.\n",
                "    #     - Vm_pv_lp_t0: ndarray, low-pass voltage filter at t-1.\n",
                "    #     - pinj_pv_t0: ndarray, real power injection at t-1.\n",
                "    #     - qinj_pv_t0: ndarray, reactive power injection at t-1.\n",
                "    #     - target_phase: int, phase being controlled (default = 2 for phase B).\n",
                "\n",
                "    #     Returns:\n",
                "    #     - PV_inj: ndarray, complex power injection at each PV node.\n",
                "    #     - Vm_pv_lp_t1: ndarray, updated low-pass filtered voltage.\n",
                "    #     - pinj_pv_t1: ndarray, updated real power injection.\n",
                "    #     - qinj_pv_t1: ndarray, updated reactive power injection.\n",
                "\n",
                "    tau_c = 0.98\n",
                "    tau_o = 0.98\n",
                "    Vm_pv_lp_t1 = Vm_pv_lp_t0 + tau_c * (Vm_pv - Vm_pv_lp_t0)\n",
                "\n",
                "    # VW\n",
                "    eta_4 = eta[:, target_phase - 1, 3]\n",
                "    eta_5 = eta[:, target_phase - 1, 4]\n",
                "    Pw_inj = np.zeros_like(Vm_pv_lp_t1)\n",
                "    for i in range(len(Vm_pv_lp_t1)):\n",
                "        if Vm_pv_lp_t1[i] <= eta_4[i]:\n",
                "            Pw_inj[i] = pv_power[i]\n",
                "        elif Vm_pv_lp_t1[i] <= eta_5[i]:\n",
                "            Pw_inj[i] = (eta_5[i] - Vm_pv_lp_t1[i]) / (eta_5[i] - eta_4[i]) * pv_power[i]\n",
                "        else:\n",
                "            Pw_inj[i] = 0\n",
                "\n",
                "    # VV\n",
                "    qv_power = np.sqrt(np.maximum(sv_power**2 - Pw_inj**2, 0))\n",
                "    Qv_inj = VV_func(Vm_pv_lp_t1, qv_power, eta[:, target_phase - 1, :])\n",
                "\n",
                "    # Dynamic filtering\n",
                "    pinj_pv_t1 = pinj_pv_t0 + tau_o * (Pw_inj - pinj_pv_t0)\n",
                "    qinj_pv_t1 = qinj_pv_t0 + tau_o * (Qv_inj - qinj_pv_t0)\n",
                "    PV_inj = pinj_pv_t1 + 1j * qinj_pv_t1\n",
                "\n",
                "    return PV_inj, Vm_pv_lp_t1, pinj_pv_t1, qinj_pv_t1\n",
                "\n",
                "def modify_mpc(PV_inj, pv_feeder, active_power_dict, reactive_power_dict):\n",
                "\n",
                "    # Updates the DSS load model with PV injection values for power flow calculation.\n",
                "\n",
                "    # Parameters:\n",
                "    # - PV_inj: ndarray of complex power injections (one per PV).\n",
                "    # - pv_feeder: list of PV feeder names.\n",
                "    # - active_power_dict: dictionary of original active power loads.\n",
                "    # - reactive_power_dict: dictionary of original reactive power loads.\n",
                "\n",
                "    injection_map = {}\n",
                "    for i, feeder in enumerate(pv_feeder):\n",
                "        injection_map[feeder] = (np.real(PV_inj[i]), np.imag(PV_inj[i]))\n",
                "    dss.Loads.First()\n",
                "    while True:\n",
                "        name = dss.Loads.Name()\n",
                "        base_kw = active_power_dict.get(name, 0)\n",
                "        base_kvar = reactive_power_dict.get(name, 0)\n",
                "        if name in injection_map:\n",
                "            inj_kw, inj_kvar = injection_map[name]\n",
                "            new_kw = base_kw + inj_kw\n",
                "            new_kvar = base_kvar + inj_kvar\n",
                "        else:\n",
                "            new_kw = base_kw\n",
                "            new_kvar = base_kvar\n",
                "        dss.Loads.kW(new_kw)\n",
                "        dss.Loads.kvar(new_kvar)\n",
                "        if not dss.Loads.Next() > 0:\n",
                "            break\n",
                "\n",
                "def get_all_node_voltageReIm_map_afterPF():\n",
                "\n",
                "    # Returns a dictionary of real and imaginary voltage components for each node (after power flow).\n",
                "\n",
                "    # Returns:\n",
                "    # - dss_map: dict, mapping node name (e.g., 'bus.1') to (real, imag) tuple of pu voltage.\n",
                "\n",
                "    dss_map = {}\n",
                "    bus_names = dss.Circuit.AllBusNames()\n",
                "    for bus_name in bus_names:\n",
                "        dss.Circuit.SetActiveBus(bus_name)\n",
                "        dss_pus = dss.Bus.PuVoltage()\n",
                "        num_phases = int(len(dss_pus) / 2)\n",
                "        for i in range(num_phases):\n",
                "            phase_name = f\"{bus_name}.{i + 1}\"\n",
                "            real_part = dss_pus[2 * i]\n",
                "            imag_part = dss_pus[2 * i + 1]\n",
                "            dss_map[phase_name] = (real_part, imag_part)\n",
                "    return dss_map\n",
                "\n",
                "def get_pv_voltageMag(pv_feeder_reshape):\n",
                "\n",
                "    # Extracts voltage magnitude at each PV node after power flow.\n",
                "\n",
                "    # Parameters:\n",
                "    # - pv_feeder_reshape: list of strings, OpenDSS-compatible node names.\n",
                "\n",
                "    # Returns:\n",
                "    # - Vm_pvMag: ndarray of voltage magnitudes.\n",
                "\n",
                "    dss_map = get_all_node_voltageReIm_map_afterPF()\n",
                "    print(\"Example dss_map keys:\", list(dss_map.keys())[:10])\n",
                "    num_pv = len(pv_feeder_reshape)\n",
                "    Vm_pvMag = np.zeros(num_pv)\n",
                "    for idx, feeder_reshaped in enumerate(pv_feeder_reshape):\n",
                "        if feeder_reshaped in dss_map:\n",
                "            real_part, imag_part = dss_map[feeder_reshaped]\n",
                "            Vm_pvMag[idx] = abs(complex(real_part, imag_part))\n",
                "    return Vm_pvMag\n",
                "\n",
                "\n",
                "def optimal_placement_greedy(U_k, M, M_s=None):\n",
                "\n",
                "    # Greedy algorithm to choose optimal sensor placements to maximize observability.\n",
                "\n",
                "    # Parameters:\n",
                "    # - U_k: ndarray, top-k singular vectors of Y matrix (shape N x k).\n",
                "    # - M: int, number of sensors to place.\n",
                "    # - M_s: list, optional starting set of sensor indices.\n",
                "\n",
                "    # Returns:\n",
                "    # - M_s: list of selected sensor indices.\n",
                "    \n",
                "    N = U_k.shape[0]\n",
                "    if M_s is None:\n",
                "        M_s = []\n",
                "\n",
                "    M_tilde = M - len(M_s)\n",
                "    j_tilde = list(set(range(N)) - set(M_s))\n",
                "\n",
                "    for _ in range(M_tilde):\n",
                "        sigma_min_list = []\n",
                "        for j in j_tilde:\n",
                "            A = U_k[M_s + [j], :]\n",
                "            try:\n",
                "                s = svds(A, k=1, which='SM', return_singular_vectors=False)\n",
                "                sigma_min_list.append(s[0])\n",
                "            except:\n",
                "                sigma_min_list.append(0)\n",
                "\n",
                "        best_index = np.argmax(sigma_min_list)\n",
                "        selected_j = j_tilde[best_index]\n",
                "        M_s.append(selected_j)\n",
                "        j_tilde.remove(selected_j)\n",
                "\n",
                "    return M_s\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Step 7: Sensor Placement ---\n",
                "# This block of code selects an optimal set of 120 sensor locations (mu-PMUs) from the network, using a greedy algorithm\n",
                "# that starts with a predefined seed set of 30 known PV sensors.\n",
                "\n",
                "max_sensor = 120\n",
                "\n",
                "# Define known PV sensors (30 in total)\n",
                "pv_sensors_lower = [\n",
                "    'p4ulv5.1', 'p4ulv5.2', 'p4ulv6.1', 'p4ulv6.2', 'p4ulv10.1', 'p4ulv10.2',\n",
                "    'p4ulv17.1', 'p4ulv17.2', 'p4ulv18.1', 'p4ulv18.2', 'p4ulv20', 'p4ulv21.1', 'p4ulv21.2',\n",
                "    'p4ulv22.1', 'p4ulv22.2', 'p4ulv23.1', 'p4ulv23.2', 'p4ulv24.1', 'p4ulv24.2',\n",
                "    'p4ulv25.1', 'p4ulv25.2', 'p4ulv26.1', 'p4ulv26.2', 'p4ulv27', 'p4ulv28',\n",
                "    'p4ulv30.1', 'p4ulv30.2', 'p4ulv33', 'p4ulv34.1', 'p4ulv34.2'\n",
                "]\n",
                "\n",
                "# Match to canonical node names\n",
                "fixed_sensors = []\n",
                "for fs in pv_sensors_lower:\n",
                "    for sensor in Y_NodeOrder:\n",
                "        if sensor.lower() == fs:\n",
                "            fixed_sensors.append(sensor)\n",
                "            break\n",
                "\n",
                "# Define initial sensors\n",
                "initial_sensor_names = fixed_sensors\n",
                "# Convert to indices\n",
                "initial_sensor_indices = [Y_NodeOrder.index(name) for name in initial_sensor_names]\n",
                "# Run greedy optimization\n",
                "optimal_indices = optimal_placement_greedy(U_k, max_sensor, M_s=initial_sensor_indices.copy())\n",
                "# Map selected indices to node names\n",
                "all_optimal_sensors = [Y_NodeOrder[i] for i in optimal_indices]\n",
                "# For now, treat all as PMUs\n",
                "S_muPMU = all_optimal_sensors.copy()\n",
                "# Keep power meters empty, but structure remains\n",
                "S_PowerMeter = []\n",
                "# For indexing\n",
                "sensor_location_indices = [Y_NodeOrder.index(s) for s in S_muPMU]\n",
                "print(\"mu-PMU sensor count:\", len(S_muPMU))\n",
                "print(\"Power meter sensor count:\", len(S_PowerMeter))\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Step 8: Generate Dataset ---\n",
                "#   1) voltage phasors at each node at each timepoint\n",
                "#   2) attack labels at PV inverter at each timepoint\n",
                "\n",
                "#  This process is very time-consuming (~10 hours for full 35040 timepoints on a 156-node system)\n",
                "FlagGen = 0  # Set to 1 to enable data generation\n",
                "\n",
                "if FlagGen == 1:\n",
                "    # Run initial power flow to get base voltages\n",
                "    dss.run_command(\"Solve\")\n",
                "    ori_Vm_Mag = get_pv_voltageMag(pv_feeder_reshape)  # Initial voltage magnitudes at PV nodes\n",
                "    voltage_map = get_all_node_voltageReIm_map_afterPF()  # Full voltage map across all nodes\n",
                "    node_keys = list(voltage_map.keys())\n",
                "    num_node = len(dss.Circuit.YNodeOrder())  # Total number of monitored nodes\n",
                "\n",
                "    # Initialize storage arrays for voltage phasors and PV data over time\n",
                "    Vall_ReIm_store = np.empty((total_timepoints, num_node, sampling_rate), dtype=complex)\n",
                "    Vpv_mag_store = np.empty((num_pv, sampling_rate), dtype=float)\n",
                "    Ppv_store = np.empty((num_pv, sampling_rate), dtype=float)\n",
                "    Qpv_store = np.empty((num_pv, sampling_rate), dtype=float)\n",
                "    baseline_eta = eta.copy()  # Save the original control curve for later comparison\n",
                "\n",
                "    # To store attack labels at each timepoint (1 if attacked, else 0)\n",
                "    attack_label_store = np.zeros((total_timepoints, num_pv), dtype=int)\n",
                "\n",
                "    # Loop through all timepoints in the load profile\n",
                "    for time_idx in range(total_timepoints):\n",
                "        print('time index:', time_idx)\n",
                "\n",
                "        # Initialize previous real/reactive power injections for dynamic filtering\n",
                "        pinj_pv_t0 = np.zeros(num_pv)\n",
                "        qinj_pv_t0 = np.zeros(num_pv)\n",
                "\n",
                "        # Load real and reactive power demands from profile at current time\n",
                "        active_power_dict = {}\n",
                "        reactive_power_dict = {}\n",
                "        for load_name, (profile, multiplier) in load_profile_map.items():\n",
                "            parquet_path = os.path.join(load_data_folder, profile)\n",
                "            parquet_data = pd.read_parquet(parquet_path)\n",
                "            kw = parquet_data.loc[time_idx, 'total_site_electricity_kw'] * multiplier\n",
                "            kvar = parquet_data.loc[time_idx, 'total_site_electricity_kvar'] * multiplier\n",
                "            active_power_dict[load_name] = kw\n",
                "            reactive_power_dict[load_name] = kvar\n",
                "\n",
                "        # Inject physical attack by altering VV/VW curve for some PVs\n",
                "        eta_comm, _ = inject_false2(eta, pv_phase2_flags, attack_fraction=0.8)\n",
                "\n",
                "        # Label PVs as attacked if their control curve was changed\n",
                "        time_varying_label = np.zeros(num_pv, dtype=int)\n",
                "        for i in range(num_pv):\n",
                "            if pv_phase2_flags[i]:\n",
                "                if np.any(eta_comm[i, 1, :] != baseline_eta[i, 1, :]):\n",
                "                    time_varying_label[i] = 1\n",
                "        attack_label_store[time_idx, :] = time_varying_label\n",
                "\n",
                "        # Print attacked PVs (for logging/debugging)\n",
                "        attacked_pvs = [pv_feeder_reshape[i] for i in range(num_pv) if time_varying_label[i] == 1]\n",
                "        print(\"Attacked phase-2 PVs:\", attacked_pvs)\n",
                "\n",
                "        # Set initial voltage and power injection values for iterative sampling\n",
                "        Vm_pv_lp_t0 = ori_Vm_Mag\n",
                "        Vm_pv_Mag = ori_Vm_Mag\n",
                "        current_pv_power = pv_power[time_idx, :]\n",
                "\n",
                "        # For each subsample (within a timepoint), simulate system with power flow\n",
                "        for sample in range(sampling_rate):\n",
                "            # Compute new PV injections using VV and VW logic + dynamic filtering\n",
                "            PV_inj, Vm_pv_lp_t1, pinj_pv_t1, qinj_pv_t1 = VV_VW_func(\n",
                "                Vm_pv_Mag, eta_comm, current_pv_power, sv_power,\n",
                "                Vm_pv_lp_t0, pinj_pv_t0, qinj_pv_t0\n",
                "            )\n",
                "\n",
                "            # Update states for next sample\n",
                "            Vm_pv_lp_t0 = Vm_pv_lp_t1\n",
                "            pinj_pv_t0 = pinj_pv_t1\n",
                "            qinj_pv_t0 = qinj_pv_t1\n",
                "\n",
                "            # Modify the load model to include PV injections\n",
                "            modify_mpc(PV_inj, pv_feeder, active_power_dict, reactive_power_dict)\n",
                "\n",
                "            # Run power flow with updated injections\n",
                "            dss.run_command(\"Solve\")\n",
                "\n",
                "            # Measure new voltage magnitudes after PF\n",
                "            Vm_pv_Mag = get_pv_voltageMag(pv_feeder_reshape)\n",
                "\n",
                "            # Store outputs for this subsample\n",
                "            Vpv_mag_store[:, sample] = Vm_pv_Mag\n",
                "            Ppv_store[:, sample] = np.real(PV_inj)\n",
                "            Qpv_store[:, sample] = np.imag(PV_inj)\n",
                "\n",
                "    # === SAVE GENERATED DATA ===\n",
                "    # Save voltage phasors and attack labels to disk for training GCN later\n",
                "    np.save('Vall_ReIm_New.npy', Vall_ReIm_store)\n",
                "    np.save('attack_label_New.npy', attack_label_store)\n",
                "\n",
                "    # === VALIDATE SAVED DATA ===\n",
                "    VoltagePhasor = np.load('Vall_ReIm_New.npy')\n",
                "    PhysicalAttackLabel = np.load('attack_label_New.npy')\n",
                "\n",
                "    # Confirm dimensions are consistent\n",
                "    num_time, num_node, num_sample = VoltagePhasor.shape\n",
                "    print(num_time, num_node, num_sample)\n",
                "    num_time1, num_pvInverter = PhysicalAttackLabel.shape\n",
                "    print(num_time1, num_pvInverter)\n",
                "\n",
                "    # Basic sanity check\n",
                "    assert VoltagePhasor.shape[0] == PhysicalAttackLabel.shape[0], \"Mismatch in timepoints\"\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#--- Step 9: load voltage phasors (with physical attack label) (before state estimation) for GCN ---\n",
                "# the two .npy files are also included in \"PhysicalAttackDetection20250327.zip\"\n",
                "# TODO: replace with Vall_ReIm_YourName.npy if data are re-generated\n",
                "file_path1 = os.path.join(current_dir, 'Vall_ReIm_New.npy')\n",
                "# TODO: replace with attack_label_YourName.npy if data are re-generated\n",
                "file_path2 = os.path.join(current_dir, 'attack_label_New.npy')\n",
                "data_obtain = data_loader_FDIPhy(file_path1, file_path2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#--- Step 10: Noise injection and FDI attack ---\n",
                "FlagFDI = 1  # Enable flag to simulate stealthy False Data Injection (FDI) attacks\n",
                "voltage_scale_factor = 0.005  # Add small random noise to voltage measurements\n",
                "\n",
                "# === Initialize the data loader ===\n",
                "# Loads voltage phasors and attack labels from saved .npy files.\n",
                "# Y_NodeOrder helps maintain bus ordering consistency.\n",
                "data_obtain = data_loader_FDIPhy(file_path1, file_path2, Y_NodeOrder=Y_NodeOrder)\n",
                "\n",
                "# === Run physical-only or FDI-based state estimation ===\n",
                "if FlagFDI == 0:\n",
                "    # Only physical attacks are used — no FDI or sensor corruption\n",
                "    print(\"Running with physical attacks only...\")\n",
                "    save_prefix = \"Physical_Only\"\n",
                "else:\n",
                "    # Apply stealthy FDI attack + noise on voltage phasors before running MMSE state estimation\n",
                "    print(\"Running with stealthy FDI + voltage noise...\")\n",
                "\n",
                "    # This function:\n",
                "    # - Adds noise to real sensor measurements (simulating real-world PMU behavior)\n",
                "    # - Injects FDI attacks on a random subset of sensors\n",
                "    # - Reconstructs the full system state using MMSE estimation\n",
                "    # - Updates labels to reflect both physical and FDI attacks\n",
                "    data_obtain.state_est_withFDI(\n",
                "        Y_norm_sparse,                # Normalized admittance matrix (GSO)\n",
                "        sensor_location_indices,     # Indices of sensor-equipped buses\n",
                "        voltage_scale_factor=voltage_scale_factor  # Noise level in measurements\n",
                "    )\n",
                "\n",
                "    # Decide file name prefix based on whether noise is added\n",
                "    save_prefix = \"FDI_Physical_WithVoltageNoise\" if voltage_scale_factor else \"FDI_Physical\"\n",
                "\n",
                "# === Sanity checks to ensure output shape consistency ===\n",
                "_, Dimbus, _ = data_obtain.data_recover.shape  # Number of buses\n",
                "_, Dimlabel = data_obtain.label_truth.shape    # Number of labels (physical + FDI)\n",
                "\n",
                "print(\"Data recover shape:\", Dimbus)\n",
                "print(\"Label shape:\", Dimlabel)\n",
                "\n",
                "# Make sure number of buses matches Y_NodeOrder\n",
                "assert Dimbus == len(Y_NodeOrder), \"Mismatch between bus count and Y_NodeOrder\"\n",
                "\n",
                "# Expected label count = 30 PV inverters + number of mu-PMU sensors\n",
                "expected_labels = len(sensor_location_indices) + 30\n",
                "assert Dimlabel == expected_labels, f\"Expected {expected_labels} labels, got {Dimlabel}\"\n",
                "\n",
                "# === Save processed data to disk ===\n",
                "# Save MMSE-estimated voltage phasors (with FDI applied) and attack labels\n",
                "np.save(f'Vphasor_{save_prefix}.npy', data_obtain.data_recover)\n",
                "np.save(f'AttackLabel_{save_prefix}.npy', data_obtain.label_truth)\n",
                "\n",
                "# === Save run configuration metadata for future reproducibility ===\n",
                "metadata = {\n",
                "    \"total_timepoints\": total_timepoints,           # e.g., 35040\n",
                "    \"sampling_rate\": sampling_rate,                 # e.g., 20 per timepoint\n",
                "    \"pv_feeders\": pv_feeder,                        # Original PV node names\n",
                "    \"sensor_nodes\": all_optimal_sensors,            # Final sensor placement (mu-PMUs)\n",
                "    \"Y_node_order\": Y_NodeOrder                     # Global bus ordering\n",
                "}\n",
                "np.save(\"metadata_run_config.npy\", metadata)\n",
                "\n",
                "# === Print summary statistics ===\n",
                "num_time, num_node, num_sample = data_obtain.data_input_beforeSE.shape\n",
                "print(f\"Total timepoints: {num_time}\")\n",
                "print(f\"Samples per timepoint: {num_sample}\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#--- Step 11: Use generated dataset to train and test GCN"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "SMART",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.11"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
